--- block/cloop.c
+++ block/cloop.c
@@ -25,33 +25,206 @@
 #include "block/block_int.h"
 #include "qemu/module.h"
 #include <zlib.h>
+#include <lzma.h>
+
+#define CLOOP_COMPRESSOR_ZLIB  0x0
+#define CLOOP_COMPRESSOR_NONE  0x1
+#define CLOOP_COMPRESSOR_XZ    0x2
+#define CLOOP_COMPRESSOR_LZ4   0x3
+#define CLOOP_COMPRESSOR_LZO   0x4
+#define CLOOP_COMPRESSOR_ZSTD  0x5
+#define CLOOP_COMPRESSOR_LINK  0xF
+
+#define CLOOP_BLOCK_FLAGS(x)  ((unsigned int)(((x) & 0xf000000000000000LLU) >> 60))
+#define CLOOP_BLOCK_OFFSET(x)  ((x) & 0x0fffffffffffffffLLU)
 
 /* Maximum compressed block size */
 #define MAX_BLOCK_SIZE (64 * 1024 * 1024)
 
+typedef struct cloop_tail {
+	uint32_t table_size;
+	uint32_t index_size;
+	uint32_t num_blocks;
+} cloop_tail;
+
+#define CLOOP3_INDEX_SIZE(x)    ((unsigned int)((x) & 0xF))
+#define CLOOP3_BLOCKS_FLAGS(x)  ((unsigned int)((x) & 0x70) >> 4)
+
+typedef struct block_info {
+	uint64_t offset;	/* 64-bit offsets of compressed block */
+	uint32_t size;		/* 32-bit compressed block size */
+	uint32_t flags;		/* 32-bit compression flags */
+} block_info;
+
+static inline int build_index(struct block_info *offsets, unsigned long n, 
+			unsigned long block_size, unsigned global_flags)
+{
+	uint32_t *ofs32 = (uint32_t *) offsets;
+	loff_t    *ofs64 = (loff_t *) offsets;
+
+	/* v3 64bits bug: v1 assumed */
+	unsigned long	v3_64=(n+1)/2;
+	loff_t	prev;
+
+	if (ofs32[0] != 0 && ofs32[1] == 0) {
+		for (prev=le64_to_cpu(ofs64[v3_64]);
+		     v3_64 > 0 && le64_to_cpu(ofs64[--v3_64]) < prev;
+		     prev=le64_to_cpu(ofs64[v3_64]));
+	}
+
+	if (ofs32[0] == 0) {
+		if (ofs32[2]) { /* ACCELERATED KNOPPIX V1.0 */
+			while (n--) {
+				offsets[n].offset = be64_to_cpu(offsets[n].offset);
+				offsets[n].size = be32_to_cpu(offsets[n].size);
+				offsets[n].flags = 0;
+        			if (offsets[n].size > 2 * MAX_BLOCK_SIZE)
+        				return n+1;
+			}
+		}
+		else { /* V2.0/V4.0 */
+			loff_t last = CLOOP_BLOCK_OFFSET(be64_to_cpu(ofs64[n]));
+			uint32_t flags;
+			unsigned long i = n;
+
+			for (flags = 0; n-- ;) {
+				loff_t data = be64_to_cpu(ofs64[n]); 
+
+				offsets[n].size = last - 
+					(offsets[n].offset = CLOOP_BLOCK_OFFSET(data)); 
+        			if (offsets[n].size > 2 * MAX_BLOCK_SIZE)
+        				return n+1;
+				last = offsets[n].offset;
+				offsets[n].flags = CLOOP_BLOCK_FLAGS(data); 
+				flags |= 1 << offsets[n].flags;
+			}
+			if (flags > 1) {
+				while (i--) {
+					if (offsets[i].flags == CLOOP_COMPRESSOR_LINK) {
+						offsets[i] = offsets[offsets[i].offset];
+					}
+				}
+			}
+		}
+	}
+	else if (ofs32[1] == 0 && v3_64 == 0) { /* V1.0 */
+		loff_t last = le64_to_cpu(ofs64[n]);
+		while (n--) {
+			offsets[n].size = last - 
+				(offsets[n].offset = le64_to_cpu(ofs64[n])); 
+        		if (offsets[n].size > 2 * MAX_BLOCK_SIZE)
+        			return n+1;
+			last = offsets[n].offset;
+			offsets[n].flags = 0;
+		}
+	}
+	else if (be32_to_cpu(ofs32[0]) == (4*n) + 0x8C) { /* V0.68 */
+		loff_t last = be32_to_cpu(ofs32[n]);
+		while (n--) {
+			offsets[n].size = last - 
+				(offsets[n].offset = be32_to_cpu(ofs32[n])); 
+        		if (offsets[n].size > 2 * MAX_BLOCK_SIZE)
+        			return n+1;
+			last = offsets[n].offset;
+			offsets[n].flags = 0;
+		}
+	}
+	else { /* V3.0 */
+		unsigned long i;
+		loff_t j;
+		
+		v3_64 = (ofs32[1] == 0) ? 2 : 1;
+		for (i = n; i-- > 0; ) {
+			offsets[i].size = be32_to_cpu(ofs32[i*v3_64]); 
+			if ((offsets[i].size & 0x80000000) == 0 &&
+        		    offsets[i].size > 2 * MAX_BLOCK_SIZE)
+        			return i+1;
+		}
+		for (i = 0, j = 128 + 4 + 4; i < n; i++) {
+			offsets[i].offset = j;
+			offsets[i].flags = global_flags;
+			if (offsets[i].size == 0xFFFFFFFF) {
+				offsets[i].flags = CLOOP_COMPRESSOR_NONE;
+				offsets[i].size = block_size;
+			}
+			if ((offsets[i].size & 0x80000000) == 0) {
+				j += offsets[i].size;
+			}
+		}
+		for (i = 0; i < n; i++) {
+			if (offsets[i].size & 0x80000000) {
+				offsets[i] = offsets[offsets[i].size & 0x7FFFFFFF];
+			}
+		}
+	}
+	return 0;
+}
+
 typedef struct BDRVCloopState {
     CoMutex lock;
     uint32_t block_size;
     uint32_t n_blocks;
-    uint64_t *offsets;
+    block_info *offsets;
     uint32_t sectors_per_block;
     uint32_t current_block;
     uint8_t *compressed_block;
     uint8_t *uncompressed_block;
     z_stream zstream;
+    int global_flags;
 } BDRVCloopState;
 
 static int cloop_probe(const uint8_t *buf, int buf_size, const char *filename)
 {
-    const char *magic_version_2_0 = "#!/bin/sh\n"
-        "#V2.0 Format\n"
+    static const uint8_t magic[] =
         "modprobe cloop file=$0 && mount -r -t iso9660 /dev/cloop $1\n";
-    int length = strlen(magic_version_2_0);
-    if (length > buf_size) {
-        length = buf_size;
+    int ret = 0, length = buf_size;
+    int i;
+
+    if (length > 127) {
+        length = 127;
+    }
+    for (i = 0; i < length - sizeof(magic) + 1; i++) {
+	if (buf[i] != magic[0]) continue;
+	if (memcmp(buf + i, magic, sizeof(magic) - 1)) continue;
+	ret = 2;
+	break;
     }
-    if (!memcmp(magic_version_2_0, buf, length)) {
-        return 2;
+    return ret;
+}
+
+static uint32_t cloop_unpack(BDRVCloopState *s, int flag)
+{
+    int ret;
+    size_t src_pos;
+    size_t dest_pos;
+    uint64_t memlimit;
+    uint32_t outlen = s->zstream.total_out;
+
+    switch (flag) {
+    case CLOOP_COMPRESSOR_ZLIB:
+        ret = inflateReset(&s->zstream);
+        if (ret != Z_OK) {
+            return 0;
+        }
+        ret = inflate(&s->zstream, Z_FINISH);
+        if (ret != Z_STREAM_END || s->zstream.total_out != outlen) {
+            return 0;
+        }
+        return outlen;
+    case CLOOP_COMPRESSOR_NONE:
+	memcpy(s->zstream.next_out, s->zstream.next_in, s->zstream.avail_in);
+	return s->zstream.avail_in;
+    case CLOOP_COMPRESSOR_XZ:
+        src_pos = 0;
+        dest_pos = 0;
+        memlimit = 32*1024*1024;
+        ret = lzma_stream_buffer_decode(&memlimit, 0, NULL, s->zstream.next_in, &src_pos,
+		 s->zstream.avail_in, s->zstream.next_out, &dest_pos, s->zstream.total_out);
+
+        if(ret != LZMA_OK || s->zstream.avail_in != (int) src_pos) {
+            return 0;
+	}
+	return dest_pos;
     }
     return 0;
 }
@@ -60,7 +233,7 @@
                       Error **errp)
 {
     BDRVCloopState *s = bs->opaque;
-    uint32_t offsets_size, max_compressed_block_size = 1, i;
+    uint32_t offsets_size, max_compressed_block_size = 1;
     int ret;
 
     bs->read_only = 1;
@@ -91,79 +264,92 @@
                    MAX_BLOCK_SIZE / (1024 * 1024));
         return -EINVAL;
     }
-
     ret = bdrv_pread(bs->file, 128 + 4, &s->n_blocks, 4);
     if (ret < 0) {
         return ret;
     }
     s->n_blocks = be32_to_cpu(s->n_blocks);
 
-    /* read offsets */
-    if (s->n_blocks > (UINT32_MAX - 1) / sizeof(uint64_t)) {
-        /* Prevent integer overflow */
-        error_setg(errp, "n_blocks %u must be %zu or less",
-                   s->n_blocks,
-                   (UINT32_MAX - 1) / sizeof(uint64_t));
-        return -EINVAL;
-    }
-    offsets_size = (s->n_blocks + 1) * sizeof(uint64_t);
-    if (offsets_size > 512 * 1024 * 1024) {
-        /* Prevent ridiculous offsets_size which causes memory allocation to
-         * fail or overflows bdrv_pread() size.  In practice the 512 MB
-         * offsets[] limit supports 16 TB images at 256 KB block size.
-         */
-        error_setg(errp, "image requires too many offsets, "
-                   "try increasing block size");
-        return -EINVAL;
-    }
-    s->offsets = g_malloc(offsets_size);
+    /* initialize zlib engine */
+    max_compressed_block_size =  s->block_size + s->block_size/1000 + 12 + 4;
+    s->compressed_block = g_malloc(max_compressed_block_size + 1);
+    s->uncompressed_block = g_malloc(s->block_size);
 
-    ret = bdrv_pread(bs->file, 128 + 4 + 4, s->offsets, offsets_size);
-    if (ret < 0) {
+    if (inflateInit(&s->zstream) != Z_OK) {
+        ret = -EINVAL;
         goto fail;
     }
 
-    for (i = 0; i < s->n_blocks + 1; i++) {
-        uint64_t size;
+    /* read offsets */
+    if (s->n_blocks + 1 == 0) {
+        cloop_tail tail;
+        int64_t end = bdrv_getlength(bs->file);
+	void *p;
+	uint32_t toclen, len; 
 
-        s->offsets[i] = be64_to_cpu(s->offsets[i]);
-        if (i == 0) {
-            continue;
+        ret = bdrv_pread(bs->file, end - sizeof(tail), &tail, sizeof(tail));
+        if (ret < 0) {
+            goto fail;
         }
 
-        if (s->offsets[i] < s->offsets[i - 1]) {
-            error_setg(errp, "offsets not monotonically increasing at "
-                       "index %u, image file is corrupt", i);
-            ret = -EINVAL;
-            goto fail;
+        s->n_blocks = be32_to_cpu(tail.num_blocks);
+        offsets_size = s->n_blocks * sizeof(block_info);
+        if (offsets_size > 512 * 1024 * 1024) {
+            /* Prevent ridiculous offsets_size which causes memory allocation to
+             * fail or overflows bdrv_pread() size.  In practice the 512 MB
+             * offsets[] limit supports 16 TB images at 256 KB block size.
+             */
+            error_setg(errp, "image requires too many offsets, "
+                       "try increasing block size");
+            return -EINVAL;
         }
+	len = be32_to_cpu(tail.table_size);
+	toclen = CLOOP3_INDEX_SIZE(be32_to_cpu(tail.index_size)) * s->n_blocks;
+	s->global_flags = CLOOP3_BLOCKS_FLAGS(be32_to_cpu(tail.index_size));
 
-        size = s->offsets[i] - s->offsets[i - 1];
+        s->offsets = g_malloc(offsets_size);
+	p = g_malloc(len);
 
-        /* Compressed blocks should be smaller than the uncompressed block size
-         * but maybe compression performed poorly so the compressed block is
-         * actually bigger.  Clamp down on unrealistic values to prevent
-         * ridiculous s->compressed_block allocation.
-         */
-        if (size > 2 * MAX_BLOCK_SIZE) {
-            error_setg(errp, "invalid compressed block size at index %u, "
-                       "image file is corrupt", i);
+        ret = bdrv_pread(bs->file, end - sizeof(tail) - len, p, len);
+        if (ret < 0) {
+            goto fail;
+        }
+        s->zstream.next_in = p;
+        s->zstream.avail_in = len;
+        s->zstream.next_out = s->offsets;
+        s->zstream.avail_out = toclen;
+	if (cloop_unpack(s, s->global_flags) == 0) {
             ret = -EINVAL;
             goto fail;
         }
+	g_free(p);
+    }
+    else {
+        offsets_size = s->n_blocks * sizeof(block_info);
+        if (offsets_size > 512 * 1024 * 1024) {
+            /* Prevent ridiculous offsets_size which causes memory allocation to
+             * fail or overflows bdrv_pread() size.  In practice the 512 MB
+             * offsets[] limit supports 16 TB images at 256 KB block size.
+             */
+            error_setg(errp, "image requires too many offsets, "
+                       "try increasing block size");
+            return -EINVAL;
+        }
+        s->offsets = g_malloc(offsets_size);
 
-        if (size > max_compressed_block_size) {
-            max_compressed_block_size = size;
+        ret = bdrv_pread(bs->file, 128 + 4 + 4, s->offsets, offsets_size);
+        if (ret < 0) {
+            goto fail;
         }
     }
-
-    /* initialize zlib engine */
-    s->compressed_block = g_malloc(max_compressed_block_size + 1);
-    s->uncompressed_block = g_malloc(s->block_size);
-    if (inflateInit(&s->zstream) != Z_OK) {
+    ret = build_index(s->offsets, s->n_blocks, s->block_size, s->global_flags);
+    if (ret) {
+        error_setg(errp, "invalid compressed block size at index %u, "
+                   "image file is corrupt", ret-1);
         ret = -EINVAL;
         goto fail;
     }
+
     s->current_block = s->n_blocks;
 
     s->sectors_per_block = s->block_size/512;
@@ -184,10 +370,10 @@
 
     if (s->current_block != block_num) {
         int ret;
-        uint32_t bytes = s->offsets[block_num + 1] - s->offsets[block_num];
+        uint32_t bytes = s->offsets[block_num].size;
 
-        ret = bdrv_pread(bs->file, s->offsets[block_num], s->compressed_block,
-                         bytes);
+        ret = bdrv_pread(bs->file, s->offsets[block_num].offset,
+			 s->compressed_block, bytes);
         if (ret != bytes) {
             return -1;
         }
@@ -196,12 +382,7 @@
         s->zstream.avail_in = bytes;
         s->zstream.next_out = s->uncompressed_block;
         s->zstream.avail_out = s->block_size;
-        ret = inflateReset(&s->zstream);
-        if (ret != Z_OK) {
-            return -1;
-        }
-        ret = inflate(&s->zstream, Z_FINISH);
-        if (ret != Z_STREAM_END || s->zstream.total_out != s->block_size) {
+	if (cloop_unpack(s, s->offsets[block_num].flags) == 0) {
             return -1;
         }
 
--- block/Makefile.objs
+++ block/Makefile.objs
@@ -35,5 +35,5 @@
 gluster.o-libs     := $(GLUSTERFS_LIBS)
 ssh.o-cflags       := $(LIBSSH2_CFLAGS)
 ssh.o-libs         := $(LIBSSH2_LIBS)
-qcow.o-libs        := -lz
+qcow.o-libs        := -lz -llzma
 linux-aio.o-libs   := -laio
--- block/cloop.c
+++ block/cloop.c
@@ -48,7 +48,6 @@
 } cloop_tail;
 
 #define CLOOP3_INDEX_SIZE(x)    ((unsigned int)((x) & 0xF))
-#define CLOOP3_BLOCKS_FLAGS(x)  ((unsigned int)((x) & 0x70) >> 4)
 
 typedef struct block_info {
 	uint64_t offset;	/* 64-bit offsets of compressed block */
@@ -57,7 +56,7 @@
 } block_info;
 
 static inline int build_index(struct block_info *offsets, unsigned long n, 
-			unsigned long block_size, unsigned global_flags)
+			unsigned long block_size)
 {
 	uint32_t *ofs32 = (uint32_t *) offsets;
 	loff_t    *ofs64 = (loff_t *) offsets;
@@ -118,42 +117,44 @@
 			offsets[n].flags = 0;
 		}
 	}
-	else if (be32_to_cpu(ofs32[0]) == (4*n) + 0x8C) { /* V0.68 */
-		loff_t last = be32_to_cpu(ofs32[n]);
-		while (n--) {
-			offsets[n].size = last - 
-				(offsets[n].offset = be32_to_cpu(ofs32[n])); 
-        		if (offsets[n].size > 2 * MAX_BLOCK_SIZE)
-        			return n+1;
-			last = offsets[n].offset;
-			offsets[n].flags = 0;
-		}
-	}
-	else { /* V3.0 */
+	else { /* V3.0 or V0.68 */
 		unsigned long i;
 		loff_t j;
 		
-		v3_64 = (ofs32[1] == 0) ? 2 : 1;
+		for (i = 0; i < n && be32_to_cpu(ofs32[i]) < be32_to_cpu(ofs32[i+1]); i++);
+		if (i == n && be32_to_cpu(ofs32[0]) == (4*n) + 0x8C) { /* V0.68 */
+			loff_t last = be32_to_cpu(ofs32[n]);
+			while (n--) {
+				offsets[n].size = last - 
+					(offsets[n].offset = be32_to_cpu(ofs32[n])); 
+	        		if (offsets[n].size > 2 * MAX_BLOCK_SIZE)
+        				return n+1;
+				last = offsets[n].offset;
+				offsets[n].flags = 0;
+			}
+			return 0;
+		}
+		
+		v3_64 = (ofs32[1] == 0);
 		for (i = n; i-- > 0; ) {
-			offsets[i].size = be32_to_cpu(ofs32[i*v3_64]); 
-			if ((offsets[i].size & 0x80000000) == 0 &&
-        		    offsets[i].size > 2 * MAX_BLOCK_SIZE)
+			offsets[i].size = be32_to_cpu(ofs32[i << v3_64]); 
+			if (offsets[i].size == 0xFFFFFFFF) {
+				offsets[i].size = 0x10000000 | block_size;
+			}
+			offsets[i].flags = (offsets[i].size >> 28);
+			offsets[i].size &= 0x0FFFFFFF; 
+			if (offsets[i].size > 2 * MAX_BLOCK_SIZE)
         			return i+1;
 		}
 		for (i = 0, j = 128 + 4 + 4; i < n; i++) {
 			offsets[i].offset = j;
-			offsets[i].flags = global_flags;
-			if (offsets[i].size == 0xFFFFFFFF) {
-				offsets[i].flags = CLOOP_COMPRESSOR_NONE;
-				offsets[i].size = block_size;
-			}
-			if ((offsets[i].size & 0x80000000) == 0) {
+			if (offsets[i].flags < 8) {
 				j += offsets[i].size;
 			}
 		}
 		for (i = 0; i < n; i++) {
-			if (offsets[i].size & 0x80000000) {
-				offsets[i] = offsets[offsets[i].size & 0x7FFFFFFF];
+			if (offsets[i].flags >= 8) {
+				offsets[i] = offsets[offsets[i].size];
 			}
 		}
 	}
@@ -170,7 +171,6 @@
     uint8_t *compressed_block;
     uint8_t *uncompressed_block;
     z_stream zstream;
-    int global_flags;
 } BDRVCloopState;
 
 static int cloop_probe(const uint8_t *buf, int buf_size, const char *filename)
@@ -305,7 +305,6 @@
         }
 	len = be32_to_cpu(tail.table_size);
 	toclen = CLOOP3_INDEX_SIZE(be32_to_cpu(tail.index_size)) * s->n_blocks;
-	s->global_flags = CLOOP3_BLOCKS_FLAGS(be32_to_cpu(tail.index_size));
 
         s->offsets = g_malloc(offsets_size);
 	p = g_malloc(len);
@@ -316,9 +315,9 @@
         }
         s->zstream.next_in = p;
         s->zstream.avail_in = len;
-        s->zstream.next_out = s->offsets;
+        s->zstream.next_out = (void *) s->offsets;
         s->zstream.avail_out = toclen;
-	if (cloop_unpack(s, s->global_flags) == 0) {
+	if (cloop_unpack(s, CLOOP_COMPRESSOR_ZLIB) == 0) {
             ret = -EINVAL;
             goto fail;
         }
@@ -342,7 +341,7 @@
             goto fail;
         }
     }
-    ret = build_index(s->offsets, s->n_blocks, s->block_size, s->global_flags);
+    ret = build_index(s->offsets, s->n_blocks, s->block_size);
     if (ret) {
         error_setg(errp, "invalid compressed block size at index %u, "
                    "image file is corrupt", ret-1);
